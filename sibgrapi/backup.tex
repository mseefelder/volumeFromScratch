%==========================================
%
% Sibgrapi 2014 paper
% Anderson Rocha, Diego Nehab, ...
%
%==========================================


% Note that the a4paper option is mainly intended so that authors in
% countries using A4 can easily print to A4 and see how their papers will
% look in print - the typesetting of the document will not typically be
% affected with changes in paper size (but the bottom and side margins will).
% Use the testflow package mentioned above to verify correct handling of
% both paper sizes by the user's LaTeX system.
%
% Also note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.
%
\documentclass[10pt, conference]{IEEEtran}

% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/oberdiek/
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 4.0 (2003-05-27) and later if using hyperref.sty. cite.sty does
% not currently provide for hyperlinked citations.
% The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/cite/
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\usepackage{subimages}
\setfigdir{figs}




% *** MATH PACKAGES ***
%
\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/
\usepackage{amsthm}
\newtheorem{definition}{Definition}





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


%\usepackage{mdwmath}
%\usepackage{mdwtab}
% Also highly recommended is Mark Wooding's extremely powerful MDW tools,
% especially mdwmath.sty and mdwtab.sty which are used to format equations
% and tables, respectively. The MDWtools set is already installed on most
% LaTeX systems. The lastest version and documentation is available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/mdwtools/


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.


%\usepackage{eqparbox}
% Also of notable interest is Scott Pakin's eqparbox package for creating
% (automatically sized) equal width boxes - aka "natural width parboxes".
% Available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/eqparbox/



% *** PDF, URL AND HYPERLINK PACKAGES ***
%
\usepackage{hyperref}





% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{Real Time Ray Casting Volume Rendering using GLSL}

%------------------------------------------------------------------------- 
% change the % on next lines to produce the final camera-ready version 
\newif\iffinal
%\finalfalse
\finaltrue
\newcommand{\jemsid}{99999}
%------------------------------------------------------------------------- 

% author names and affiliations
% use a multiple column layout for up to two different
% affiliations

\iffinal
  \author{%
    \IEEEauthorblockN{Marcos Araujo}
    \IEEEauthorblockA{%
      Polytechnic school - UFRJ\\
      Rio de Janeiro, Brazil
      Email:  \href{mailto:marcos.araujo@poli.ufrj.br}{marcos.araujo@poli.ufrj.br}}
  \and
    \IEEEauthorblockN{Ricardo Marroquim}
    \IEEEauthorblockA{%
      COPPE - UFRJ\\
      Rio de Janeiro, Brazil\\
      Email:  \href{mailto:marroquim@cos.ufrj.br}{marroquim@cos.ufrj.br}}
  }
\else
  \author{Sibgrapi paper ID: \jemsid \\ }
\fi

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3}, 
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}


%------------------------------------------------------------------------- 
% Special Sibgrapi teaser
\teaser{%
  \oneimage{Teasing result of our method: from this data input (left), the relevant feature are extracted using our technique (middle), producing effective result (right).}{.99}{teaser.pdf}
}
%------------------------------------------------------------------------- 



% make the title area
\maketitle


\begin{abstract}
Our work consists on the development of an OpenGL 4 application capable of real-time volume rendering, taking full advantage of GPU shader programming with GLSL 4.3, for both image composition and volume processing. 

The application allows for interactive scalar volumetric datasets visualization with lighting and color, being the latter obtained through a 2D transfer function.

% DO NOT USE SPECIAL CHARACTERS, SYMBOLS, OR MATH IN YOUR TITLE OR ABSTRACT.
%
\end{abstract}

\begin{IEEEkeywords}
volume rendering; ray casting; transfer functions;

\end{IEEEkeywords}


\IEEEpeerreviewmaketitle


% Wherever Times is specified, Times Roman or Times New Roman may be used. If neither is available on your system, please use the font closest in appearance to Times. Avoid using bit-mapped fonts if possible. True-Type 1 or Open Type fonts are preferred. Please embed symbol fonts, as well, for math, etc.

%==========================================
%==========================================


%==========================================
\section{Introduction}
In computer graphics a volume can be represented as a tridimensional matricial structure, composed by voxels, which are analogous to pixels in a bidimensional image. Such data structures, also called \textit{datasets}, are generated by procedures such as computed tomographies (CT) magnetic resonance imaging (MRI), or simulations, like data obtained from computational fluid dynamics (CFD). These visualizations are used in fields like archeology, medicine and physics.


Rendering these volumes in the clearest way possible is important to allow a good understanding of the analyzed datasets and their characteristics. The goal of this project is to provide a real-time rendering with illumination, as well as the option to use specific transfer functions.


The methods used for the application development are based on OpenGL4, and shader programming in GLSL using the ShaderLib Library\cite{shaderlib}. This library is a wrapper for modern OpenGL programming, unburdening the developer from repetitive setups and tracking OpenGL's state variables.

In Section\ref{sec:volrender} we present volume rendering concepts, and discuss the ray-casting method in Section\ref{sec:raycasting}. Application results are presented in Section\ref{sec:results} and we conclude the work in Section\ref{sec:conclusion}.

%==========================================
\section{Volume Rendering}
\label{sec:volrender}

In our application domain, volume rendering consists in taking a scalar volumetric dataset and processing it to output intelligible images. The datasets are tridimensional voxel matrices, usually composed by 2D layers. The size of the layers and their spacing are dependent on the dataset.


In order to represent a volume, it is necessary to sample it continuously, even though it is structured as a discrete grid. This continuous sampling is possible through the interpolation of the scalar values. Given any chosen point in the volume's space, its value can be determined by the trilinear interpolation of the point's eight nearest neighbors. As we are working with \textit{3D textures}, this interpolation comes for free since it is directly supported by the graphics software.


There are many methods that can be used to render a scalar volumetric dataset, some described in \cite{RTVR} and many analyzed in \cite{survey}. The method chosen for this project is the GPU-Based Ray Casting with local gradient-based illumination and color determination through transfer functions.



%==========================================
\section{Ray Casting}
\label{sec:raycasting}

The GPU-Based Ray Casting method consists, in the case of an orthographic camera setup, in "shooting" a parallel ray matrix through the volume, each ray being cast from one of the image's pixels. Along each ray, the volume is sampled several times in different discrete positions, as if it was "walking" with a fixed step size. These sampled values are mapped to certain optical properties by the transfer function, used to compose the pixel's final color. See Figure~\ref{fig:ray} for an illustration of the method.

\begin{figure}[h]
\centering
\includegraphics[width=3in]{raycasting.png}
\caption{Representation of the Ray Casting setup.}
\label{fig:ray}
\end{figure}

In the following subsections we will explain how we approached this method in terms of the scene setup with OpenGL 4 and ShaderLib, how the color composition works and the method we used for illumination.


\subsection{Rendering space setup}
\label{sec:rss}

The setup consists in representing the volume as a parallelepiped in the world space's origin, the camera's image plane, and a light source positioned in space. No vertex structure is created for the volume, because our representation is implicit since we only need to know the parallelepiped's dimensions.

The plane is a square with the sides as large as the parallelepiped's greater diagonal. Its distance from the world's center is always half of this diagonal, so, the volume is never clipped out of the viewport. This plane can be rotated around the volume using the trackball system implemented in the ShaderLib. The plane is created as a simple mesh with four vertices.

\subsection{Transfer functions}
\label{sec:tf}

In our project we calculate a gradient field for the volume (Section\ref{sec:gradient}). In each sampled position we acquire a four component vector consisting of the gradient vector (three components), and the scalar value that comes from the original dataset. This scalar value and the magnitude of the gradient vector are used to map a set of optical properties in the two-dimensional transfer function.

\begin{figure}[h]
\centering
\includegraphics[width=3in]{tfeng.png}
\caption{Example: transfer function mapping two parameters.}
\label{fig:tf}
\end{figure}

The transfer function is a way to make sense out of the abstract data represented in the dataset. It maps the scalar value and the gradient vector's magnitude to a two-dimensional matrix of 4-component vectors, containing a color (3-component vector) and an opacity value, wich are the optical properties used to calculate the propagation of light inside the volume. Figure~\ref{fig:tf} depicts a 2d transfer function. In this case, we are considering absorption-only volumes, so no emission or scattering is taken into account.


\subsection{Volume sampling}
\label{sec:volsampling}

The sampling inside the volume is done during rendering in the fragment shader. As it is recommended in \cite{RTVR}, the number of samples taken inside the volume is two times the number of voxels in the largest dimension of the volumetric dataset. So, if the volume has 250 layers in height, 150 layers in width and 300 layers in depth, we sample the volume 600 times for each ray.

Each ray is casted from a pixel of the image plane, so to sample the volume in a specific time step we have to know what are the world coordinates for the pixel, the direction pointed by the rendering plane and the step size.

\begin{figure}[h]
\centering
\includegraphics[width=3in]{uvecs.png}
\caption{The unit vectors in relation to the plane.}
\label{fig:uvecs}
\end{figure}

First we convert from pixel coordinates to the plane's local coordinate system. We normalize the pixel coordinate to a value $\vec{pixPos}$ $\in$ $[0.0, 1.0]$, (where the pixel $(0,0)$ is at the lower left corner of the image). Then, with the plane's dimension (\(pSide\)), we calculate the position in relation to the plane coordinate system (where now position $(0,0)$ is in the plane's center):


\[\vec{p} = ((\vec{pixPos} \times 2)-1) \times (pSide)\]


Knowing the rendering plane's origin (its center) in world coordinates (\(\vec{rPlane}\)), the pixel's world position (\(\vec{pixWPos}\)) is defined as:


\[\vec{pixWPos} = \vec{rPlane}+(p \cdot \hat{e_0} \times \hat{v_w})+(p \cdot \hat{e_1} \times \hat{v_h})\]

Where \(\hat{v_w}\) and \(\hat{v_h}\) are the plane's tangent unit vectors, as illustrated in Figure~\ref{fig:uvecs}. The steps are taken in the direction of \(\hat{v_d}\) (depth vector), that points to the world's origin. $\hat{e_0}$ and $\hat{e_1}$ are the canonical unit vectors $(1, 0, 0)$ and $(0, 1, 0)$, respectively.

\subsection{Gradient calculation}
\label{sec:gradient}


To provide another parameter for the two-dimensional transfer function and to compute lighting effects, we calculate a gradient field for the volume.

\begin{figure}[h]
\centering
\includegraphics[width=3in]{neighbors.png}
\caption{Representation of a voxel and it's six nearest neighbors.}
\label{fig:interp}
\end{figure}

Considering Figure~\ref{fig:interp} we calculate the gradient vector for a voxel using its six nearest neighbors as follows:

\[\vec{grad} = (v4,v3, v1)-(v2, v5, v6)\]

This operation is carried out inside \textit{compute shader} that dispatches one instance per voxel. It is executed during the application setup, so it computes the entire gradient field for the volume in a pre-processing stage.

To smooth the noise present in the gradient field, we apply a simple filtering via \textit{compute shader}: we calculate the medium vector between each voxel and its six nearest neighbors. Refer to Figure~\ref{fig:suave} for a comparison between non-smoothed and smoothed gradient fields.

\begin{figure}[h]
\centering
\includegraphics[width=3.5in]{smooth.png}
\caption{Comparing renderings of the original gradient field (left) and the smoothed (right)}
\label{fig:suave}
\end{figure}

\subsection{Color and gradient composition}
\label{sec:cgc}

Along each ray, the Ray Casting algorithm samples points inside the volume, acquiring a four component vector (\(\vec{voxelValue}\)), where the first three components define the gradient vector, and the last is the scalar value. The gradient vector's magnitude and this scalar value are used to map a RGBA vector (\(\vec{curVector}\)) in the transfer function. 
We consider a scalar floating point value \(transp\) as the ray's transparency (alpha channel).
The algorithm to composite these vectors in a final accumulated color (\(\vec{AcColor}\)) for each ray (therefore, each pixel) is:

\textit{For each step:}


\[transp = AcColor.A;\]

\[\vec{AcColor} = \vec{AcColor} + (1.0 - transp) \times \vec{curVector};\]

We also compose the gradient vector (\(\vec{AccGradient}\)), in order to use  during illumination calculation (described in the next subsection), in the following way:

\textit{If (\(AccGradient.A < 1\)) and (\(curVector.A \neq 0\)):}


\[\vec{AccGradient} = \vec{AccGradient} + (1.0 - transp) \times \vec{voxelValue};\]


\subsection{Illumination}
\label{sec:ill}

For illumination we are using a simplified version of the Phong shader presented in \cite{RTVR}, in which we are just calculating the diffuse illumination component (\(\vec{diff}\)) for each pixel based on the normalised vector composed of the gradient vectors accumulated (\(\hat{AccGradient}\)), the light source position (\(\vec{LightPos}\)) and the accumulated color for the pixel (\(\vec{AcColor}\)) as follows:


\[\vec{diff} = \vec{AcColor} \times max(\vec{LightPos} \times \hat{AccGradient}.xyz, 0.0)\]

Where \(max()\), returns the maximum value of two given parameters.



%==========================================
\section{Results}
\label{sec:results}

The following figures (\ref{fig:bones}, \ref{fig:tf2D}, \ref{fig:gerais}) represent some of the application's results:

\begin{figure}[h]
\centering
\includegraphics[width=3.5in]{01-ossos.png}
\caption{Rendered from the CT dataset of a foot, emphasizing the bones with the use of an adequate transfer function. The light source position is different from one image to another.}
\label{fig:bones}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=3.5in]{02-tf2D.png}
\caption{Example of an arbitrary transfer function in use to render two different volumes. The transfer function's color are represented in the lower right corner, with no representation of the alpha channel.}
\label{fig:tf2D}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=3.5in]{03-gerais.png}
\caption{Two more images using two different transfer functions. The one in the left exemplifies the possibility of seeing the bones through the flesh. The one in the right was adjusted to give the bonsai it's original colors.}
\label{fig:gerais}
\end{figure}


%==========================================
\section{Conclusion and future works}
\label{sec:conclusion}

Conclusion goes here.



%==========================================
\iffinal
% use section* for acknowledgement
\section*{Acknowledgment}
%
Acknowledge the knowledge.
\fi



%==========================================

% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

\bibliographystyle{IEEEtran}
\bibliography{example}

%\emph{SIBGRAPI 2014, Proceedings of the XXVII Brazilian Symposium on Computer Graphics and Image Processing}.\hskip 1em plus 0.5em minus 0.4em\relax  Rio de Janeiro, Brazil: {IEEE}, August 2014.

\end{document}